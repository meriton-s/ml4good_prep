# to do:
## colab notebooks
- colab notebook on hyperparametrs -- visualisation (to demostrate dependansies)
## readins 
- Against Almost Every Theory of Impact of Interpretability by Charbel-Raphael Segerie
https://www.alignmentforum.org/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1
## video
- watch youtube about alphaEvolve

# to desing
## evals 
- try to create a funny evals like vending-bench but about ai safety management

## colab notebook
- all the notebooks in versions: easy -- read and play normal: oneinstruction one line of code hard: explanation of rhe task + code structure scratch: instruction how to do it in user's ide)
- it would be cool to create a course there one builds NN step by step: classifier - hand -written number recognition - adverserial attacks - etc. It could kind of help keep the whole picture in one's mind
- NN fundamentals: from partial derevatives to groking:
  - MLP on numpy from scratch
  - torch 
  - hyperparamets 
  - groking & double decent 

## workshop on intro to AISR \ carrier
- Skills
  * the world will down-rate you on the lack of the following
    * networking
    * fundraising
    * public\research communication
    * technical skills (low level\grounded skills)
    * strategic\systemic views (high level understanding)
    * meta-skills (research taste, time management, self reflection and open-mindedness)
* concrete scenarios are bullshit (reading from preparation) but human mind are kinda designed to generate it. here is an attempt to use the free ability to generate plans and turn it into some estimations that makes sense. how to produce usefully scenario activities: 
  - imagine a concrete scenario
  - divide it into steps if not done before
  - start from a beginning and estimate how many equally dangerous alternatives you can name
  - repeat to each step, making a tree
  - estimate a resulting probability\likelihood or whatever you want
* you have 100m $ and 2 years -- build a strategy to solve ai safety problem
* you have a strategy -- make step by step plan to implement it
* 

## governance post
- risk classification based of what's broken not whom to blame
  - ## Risks classification
  - Balance disruption
  - Bad attractor risks
  - Singularity risks
  - Absense of AI risks
  - ## Solutions
  * Fix what exists
  
we do not fit our own standards for software with fixing tools -- it is not working properly.  
  * Build correct from the beginning

we do not have a winning approach, and we do not use best practises humanity has to generate approaches 
  * Stop doing (bigger) AI's

what progress do we have on it? ias it just talking as about the climate change?

- ## GD like dynamics 
  - what systems are most fragile? (complex? high bared?)
  - what systems are in unstable equilibrium
  - where do we transfer control
  - where are most decisions are made by ai already
  - where ai shapes human behaviour 


# to think 
## llms & space of tokens  
- LLMs are better in coding because the space of code is so much smaller than of natural level
- if that is true then it also would be true for analytic\synthetic languages? And artificial languages? And other structures with smaller space?
- it is interesting to think about all of this from the point of configuration space

## incentives of arm race
competitive pressure might work not as i use to think "if we don't do bad thing those awful guys we are competing with will do even a worse thing". But as "we don't want to lose to those awful (or any) guys we are competing with"

## hybrid architectures
- compare 
  - voyager (Wang 2023) that use gpt generating instructions and code that implement them communicating via ApI (knowing the state of the game)
  - IGOR that use llm+rl
- llm+rl worked, llm+evoAlg worked. what else can be mixed with llm?

## best go player
- what exactly is going on with alfaGo\kataGo and adversarials? the issue is that winning in go is such a complex landscape that it doesn't generalize well. but why is it so? is it something to do with sampling? or is it a nature of the task?



# to google
- i should take a look on the papers of world models in LLM (golden bridge) + "on the biology of large language models" by Anthropic

- google about figure 01 + openAI: they are doing speech reasoning in a voice controlled robot
- theory of mind benchmarks and self\others overlap
- mirror test: youtube, scholar, miriY
