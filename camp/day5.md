# day 5 

## RLHF 
https://habr.com/ru/articles/730990/
motivation:
- get rid of dataset byeses
- meet our expectation on behavior (anser questions eg)

### dataset 
RLHF relies on two datasets:
- Synthetic dialogues: Annotators authored both user and assistant turns, using prompts from an earlier GPT version.
- Ranked responses: For each prompt, annotators reviewed several assistant replies and ordered them from best to worst.
### pipeline: SFT-RM-RL
1. Supervised Fine-Tuning (SFT)
2. Preference Sampling & Reward Learning
   - Preference Sampling
   - Reward Modeling
3. Reinforcement Learning (RL) Optimization
   - The RL Objective

## reasoning model
https://huggingface.co/blog/open-r1

### Exercise: Measuring Chain of Thought faithfullness
Exercise 
https://colab.research.google.com/github/wusche1/ML4G-2.0/blob/reasoning_models/workshops/reasoning_models_faithfullness/exercise.ipynb

My copy: https://colab.research.google.com/drive/1vqetsMDh7Ek5-QN3GXLwbinIYyu46d9d

### MechInterp 
- https://colab.research.google.com/github/EffiSciencesResearch/ML4G-2.0/blob/master/workshops/transformer_interp/exercise_hard.ipynb
- https://colab.research.google.com/github/EffiSciencesResearch/ML4G-2.0/blob/master/workshops/transformer_interp/exercise_normal.ipynb

## job quality
- freedom, variety, clear tasks, feedback
- help others (make sence)
- work you are good at
- fit the demand\life habbits 
- supportive colleages

## thoery of change 
### i'm mostly worried about X
- need for methodology improvement in ai safety
- lack of working solutions 
- mess in public communications
- absense of the environmental readiness to implement pivotal ai 

## x mostly happens because of Y
- i do not know why our methodology in ai safety is so messy

- there i no example of proper way

## i can change Y by doing Z
- whom do i ask about it? who is doing ai theory?
- problem: these are kind of questions that will not make me a popular person, how do i ask them in a way i can get answers?

- show that methodology improvement is profitable thing to do 

- aidigest.com 
- 
# ideas
- do benchmark that captures human expectation: a task that model solves + tasks human suppose also will be solved if that one is done correctly 
- try to find log journals (may be camps)
- ask mentors what disappoints them in their mentees methodology
- aks other people if they have compared the best practices in safety and other fuilds 
- aks ml people on the same staff
- try anonymous survey approach
- try to talk about the best possible world methodology
  - in a perfect world what would we change in methodology
  - people don't do it for a reason what this reason is
  - find 2 people and ask them during 1-1
- 
## carrier planning 
https://www.allandafoe.com/opportunity

> i claim that almost all course projects are at list one of the following:
> - inaccurate
> - unclearly written
> - unfineshed
> - irrelevant to important topic
> - irrelevant to the key desidions needed in those topic
> - never seen by key people or hard build on them
> - not much boosting your future impact
> - not best fit for you\your mentor
> - redundunt to current\ongoing work

https://docs.google.com/document/d/1IgpZyHzSLAESIez4KL27rTJf-f9VXj7AIGG5w-4YPIw/edit?tab=t.2c93s55sniyc
https://docs.google.com/spreadsheets/d/1PaWRZSwDHxtW84LaPXswdbOu533w9meJws5JiKVE1EE/edit?gid=1529633846#gid=1529633846